{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyddm_gddm_short_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c6TMBKueemL"
      },
      "source": [
        "# Fitting the Roitman Shadlen (2002) data using PyDDM\n",
        "In this example, we load data from the open dataset by Roitman and Shadlen (2002). This dataset can be [downloaded here](https://shadlenlab.columbia.edu/resources/RoitmanDataCode.html). We use a preprocessed version below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MNzxzqJfMNn",
        "cellView": "form"
      },
      "source": [
        "#@title Prepare the environment\n",
        "!pip -q install git+https://github.com/mwshinn/PyDDM\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrM8bwmMfBjj"
      },
      "source": [
        "from ddm import Sample\n",
        "import pandas\n",
        "df_rt = pandas.read_csv(\"https://raw.githubusercontent.com/mwshinn/PyDDM/master/doc/downloads/roitman_rts.csv\")\n",
        "df_rt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9jZv9ynh_pI"
      },
      "source": [
        "Let's fit only monkey 1 for right now.  We will filter out the shortest and longest RTs as they did in Roitman and Shadlen (2002), but this is not necessary.  Finally, we use these data to create a \"sample\" object for PyDDM.  For each trial, it will contain the RT, whether the response was correct, and three conditions: the coherence (\"coh\"), the monkey (\"monkey\", here always 1), and whether they chose the left or right target (\"trgchoice\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x_I30UUh32Y"
      },
      "source": [
        "\n",
        "df_rt = df_rt[df_rt[\"monkey\"] == 1] # Only monkey 1\n",
        "  \n",
        "# Remove short and long RTs, as in 10.1523/JNEUROSCI.4684-04.2005.\n",
        "# This is not strictly necessary, but is performed here for\n",
        "# compatibility with this study.\n",
        "df_rt = df_rt[df_rt[\"rt\"] > .1] # Remove trials less than 100ms\n",
        "df_rt = df_rt[df_rt[\"rt\"] < 1.65] # Remove trials greater than 1650ms\n",
        "  \n",
        "# Create a sample object from our data.  This is the standard input\n",
        "# format for fitting procedures.  Since RT and correct/error are\n",
        "# both mandatory columns, their names are specified by command line\n",
        "# arguments.\n",
        "roitman_sample = Sample.from_pandas_dataframe(df_rt, rt_column_name=\"rt\", correct_column_name=\"correct\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPDp44H2iwCO"
      },
      "source": [
        "# Fitting a DDM using PyDDM\n",
        "First, we want to let the drift rate vary with the coherence. To do so, we must subclass Drift. Each subclass must contain a name (a short description of how drift varies), required parameters (a list of the parameters that must be passed when we initialize our subclass, i.e. parameters which are passed to the constructor), and required conditions (a list of conditions that must be present in any data when we fit data to the model). We can easily define a model that fits our needs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ic57jESi1X4"
      },
      "source": [
        "import ddm.models\n",
        "class DriftCoherence(ddm.models.Drift):\n",
        "    name = \"Drift depends linearly on coherence\"\n",
        "    required_parameters = [\"driftcoh\"] # <-- Parameters we want to include in the model\n",
        "    required_conditions = [\"coh\"] # <-- Task parameters (\"conditions\"). Should be the same name as in the sample.\n",
        "    \n",
        "    # We must always define the get_drift function, which is used to compute the instantaneous value of drift.\n",
        "    def get_drift(self, conditions, **kwargs):\n",
        "        return self.driftcoh * conditions['coh']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZvYnZWKjEdS"
      },
      "source": [
        "Because we are fitting with likelihood, we must include a baseline lapse rate to avoid taking the log of 0. Traditionally this is implemented with a uniform distribution, but PyDDM can also use an exponential distribution using OverlayPoissonMixture (representing a Poisson process lapse rate), as we use here. However, since we also want a non-decision time, we need to use two Overlay objects. To accomplish this, we can use an OverlayChain object. Then, we can construct a model which uses this and fit the data to the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTOU4e_ljHAG"
      },
      "source": [
        "from ddm import Model, Fittable\n",
        "from ddm.functions import fit_adjust_model, display_model\n",
        "from ddm.models import NoiseConstant, BoundConstant, OverlayChain, OverlayNonDecision, OverlayPoissonMixture\n",
        "model_rs = Model(name='Roitman data, drift varies with coherence',\n",
        "                 drift=DriftCoherence(driftcoh=Fittable(minval=0, maxval=20)),\n",
        "                 noise=NoiseConstant(noise=1),\n",
        "                 bound=BoundConstant(B=Fittable(minval=.1, maxval=1.5)),\n",
        "                 # Since we can only have one overlay, we use\n",
        "                 # OverlayChain to string together multiple overlays.\n",
        "                 # They are applied sequentially in order.  OverlayNonDecision\n",
        "                 # implements a non-decision time by shifting the\n",
        "                 # resulting distribution of response times by\n",
        "                 # `nondectime` seconds.\n",
        "                 overlay=OverlayChain(overlays=[OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.4)),\n",
        "                                                OverlayPoissonMixture(pmixturecoef=.02,\n",
        "                                                                      rate=1)]),\n",
        "                 dx=.001, dt=.01, T_dur=2)\n",
        "\n",
        "# Fitting this will also be fast because PyDDM can automatically\n",
        "# determine that DriftCoherence will allow an analytical solution.\n",
        "fit_model_rs = fit_adjust_model(sample=roitman_sample, model=model_rs, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJYKV0dajNC5"
      },
      "source": [
        "Now let's view the fitted model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_CBc6XejSgj"
      },
      "source": [
        "import ddm.plot\n",
        "ddm.plot.model_gui_jupyter(model=fit_model_rs, sample=roitman_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trIcW03dmWX4"
      },
      "source": [
        "display_model(fit_model_rs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXuHQgOds6k9"
      },
      "source": [
        "# Fitting a GDDM using PyDDM\n",
        "Letâ€™s see if we can improve the fit by including additional model components. We will include exponentially collapsing bounds and use a leaky or unstable integrator instead of a perfect integrator.\n",
        "\n",
        "To use a coherence-dependent leaky or unstable integrator, we can build a drift model which incorporates the position of the decision variable to either increase or decrease drift rate. This can be accomplished by making get_drift depend on the argument x.  We don't need to define collapsing bounds, because this is included by default in PyDDM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5oHTBaVtJfl"
      },
      "source": [
        "class DriftCoherenceLeak(ddm.models.Drift):\n",
        "    name = \"Leaky drift depends linearly on coherence\"\n",
        "    required_parameters = [\"driftcoh\", \"leak\"] # <-- Parameters we want to include in the model\n",
        "    required_conditions = [\"coh\"] # <-- Task parameters (\"conditions\"). Should be the same name as in the sample.\n",
        "    \n",
        "    # We must always define the get_drift function, which is used to compute the instantaneous value of drift.\n",
        "    def get_drift(self, x, conditions, **kwargs):\n",
        "        return self.driftcoh * conditions['coh'] + self.leak * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORP7o-EatLKG"
      },
      "source": [
        "Thus, the full model definition is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D04HnwaAtW1g"
      },
      "source": [
        "from ddm.models import BoundCollapsingExponential\n",
        "model_leak = Model(name='Roitman data, leaky drift varies with coherence',\n",
        "                   drift=DriftCoherenceLeak(driftcoh=Fittable(minval=0, maxval=20),\n",
        "                                            leak=Fittable(minval=-10, maxval=10)),\n",
        "                   noise=NoiseConstant(noise=1),\n",
        "                   bound=BoundCollapsingExponential(B=Fittable(minval=0.5, maxval=3),\n",
        "                                                    tau=Fittable(minval=.0001, maxval=5)),\n",
        "                   # Since we can only have one overlay, we use\n",
        "                   # OverlayChain to string together multiple overlays.\n",
        "                   # They are applied sequentially in order.  OverlayDelay\n",
        "                   # implements a non-decision time by shifting the\n",
        "                   # resulting distribution of response times by\n",
        "                   # `delaytime` seconds.\n",
        "                   overlay=OverlayChain(overlays=[OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.4)),\n",
        "                                                  OverlayPoissonMixture(pmixturecoef=.02,\n",
        "                                                                        rate=1)]),\n",
        "                   dx=.01, dt=.01, T_dur=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfzlLi9qub-5"
      },
      "source": [
        "Before we fit the model, let's take a look at what these parameters do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bii9bh8rufXA"
      },
      "source": [
        "ddm.plot.model_gui_jupyter(model=model_leak, sample=roitman_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAfa6CitePf"
      },
      "source": [
        "The function for fitting the model is shown below.  However, because this can take a few minutes (and is especially slow when running on Google Colab), we instead show a version which we already fit to data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgMSXS93tvLb"
      },
      "source": [
        "# fit_model_lk = fit_adjust_model(sample=roitman_sample, model=model_leak)\n",
        "fit_model_lk = Model(drift=DriftCoherenceLeak(driftcoh=10.718, leak=-.94),\n",
        "                     noise=NoiseConstant(noise=1),\n",
        "                     bound=BoundCollapsingExponential(B=1.557, tau=1.906),\n",
        "                     overlay=OverlayChain(overlays=[OverlayNonDecision(nondectime=.2388),\n",
        "                                                    OverlayPoissonMixture(pmixturecoef=.02, rate=1)]),\n",
        "                     dx=.01, dt=.01, T_dur=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n09SiDqt8cY"
      },
      "source": [
        "As before, we can visualize this model.  Note how this GDDM is a much better fit than the DDM we fit previously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK10kTM5uD7i"
      },
      "source": [
        "ddm.plot.model_gui_jupyter(model=fit_model_lk, sample=roitman_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1a-4iAruxMX"
      },
      "source": [
        "display_model(fit_model_rs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLiu7EJvu1-C"
      },
      "source": [
        "# Conclusion\n",
        "Hopefully this tutorial helped you see how you could use PyDDM and the GDDM in your own work.  See the documentation for more information, including the [Cookbook](https://pyddm.readthedocs.io/en/latest/cookbook/index.html), which contains a collection of plug-and-play model components you can use to build your own GDDM."
      ]
    }
  ]
}